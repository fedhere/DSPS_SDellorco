I worked on this homework discussing it with Sid, Masooma, Rayta, Paula, Miles, Tali and Christian. I also discussed some issues I ran into for the last three parts with Willow
at her office hours.

This homework delves into Gaussian Process Regression (GPR), which is a Machine Learning technique using a probabilitstic approach, and is good for estimating uncertainties.
A very important part of this process is chosing a kernel function which describes the relationship between the data. For example, the El Nino dataset used in this homework
showed a periodic relationship, which led me to choose a kernel that uses a sine function since sine is a periodic function. While there may have been a better periodic model
that could have been used in the kernel that was more mindful of the varying amplitudes of the periodic function within the data, it does capture the period of the data well.
Another use of GPR is to predict data and interpolate data using the known data. Based on the data known for one day a month for 60 years, data was interpolated using GPR for
one data point per day for 80 years (1950-2030). Then, optimization was used to find the ideal parameters of the kernel function, which yielded a very similar graph to that
in Part 2. Throughout this whole process, visualizations for the original data, GPR regression model, and optimization model were created. Since the fit model generated by the
sine squared kernel did not produce an amazing fit for the data, if I had time I would like to test different kernel models to find one that fits better. I do think that 
periodic kernels are still an ideal choice since the data is so clearly periodic. The El Nino dataset used for this homework described ocean surface temperatures measured
monthly from 1950-2010, which is typically periodic.

The most difficult part of this assignment for me was creating the gaussian_process_regression function in Part 2. While running the code I kept having colab crash because
there wasn't enough RAM, so I ended up having to start that part of Part 2 over to get it to work. Little errors can make a big difference in running the code. Even things
like making the different variables in compatable formats can really change the way a code does (or doesn't) run.

The easiest part of this assignment for me was creating and interpreting the visualizations. Understanding things conceptually has usually come easier for me in this class 
than trying to implement them in code.

One thing that I learned in this assignment was more specifics about GPR. Decisions like how to choose a kernel (covariance) function, how to make compatable variables,
and how to interpolate data were all covered in the assignment. Discussing it and having to explain myself to classmates was also very helpful.
